{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "conf = SparkConf().setAppName('appName3').setMaster('local')\n",
    "conf.set(\"spark.executor.memory\",'4G')\n",
    "conf.set(\"spark.driver.memory\",'4G')\n",
    "conf.set(\"spark.cores.max\",'4')\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Packages of Pyspark\n",
    "스파크 2.0부터 ML 패키지는 데이터프레임에 대해 작동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.types as typ\n",
    "labels = [\n",
    "    ('INFANT_ALIVE_AT_REPORT', typ.IntegerType()),\n",
    "    ('BIRTH_PLACE', typ.StringType()),\n",
    "    ('MOTHER_AGE_YEARS', typ.IntegerType()),\n",
    "    ('FATHER_COMBINED_AGE', typ.IntegerType()),\n",
    "    ('CIG_BEFORE', typ.IntegerType()),\n",
    "    ('CIG_1_TRI', typ.IntegerType()),\n",
    "    ('CIG_2_TRI', typ.IntegerType()),\n",
    "    ('CIG_3_TRI', typ.IntegerType()),\n",
    "    ('MOTHER_HEIGHT_IN', typ.IntegerType()),\n",
    "    ('MOTHER_PRE_WEIGHT', typ.IntegerType()),\n",
    "    ('MOTHER_DELIVERY_WEIGHT', typ.IntegerType()),\n",
    "    ('MOTHER_WEIGHT_GAIN', typ.IntegerType()),\n",
    "    ('DIABETES_PRE', typ.IntegerType()),\n",
    "    ('DIABETES_GEST', typ.IntegerType()),\n",
    "    ('HYP_TENS_PRE', typ.IntegerType()),\n",
    "    ('HYP_TENS_GEST', typ.IntegerType()),\n",
    "    ('INFANT_WEIGHT_GRAMS', typ.IntegerType())\n",
    "]\n",
    "\n",
    "schema = typ.StructType([typ.StructField(e[0], e[1], False) for e in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "births = spark.read.csv('births_transformed.csv.gz', header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIRTH_PLACE 컬럼 인코딩 작업\n",
    "births = births.withColumn('BIRTH_PLACE_INT', births['BIRTH_PLACE'].cast(typ.IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.feature as ft\n",
    "encoder = ft.OneHotEncoder(inputCol = 'BIRTH_PLACE_INT', outputCol='BIRTH_PALCE_VEC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresCreator = ft.VectorAssembler(inputCols=[col[0] for col in labels[2:]] + [encoder.getOutputCol()],\n",
    "                                    outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.classification as cl\n",
    "logistic = cl.LogisticRegression(maxIter=10, regParam=0.01,\n",
    "                                labelCol='INFANT_ALIVE_AT_REPORT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[encoder, featuresCreator, logistic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "births_train, births_test = births.randomSplit([0.7,0.3], seed=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(births_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = model.transform(births_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(INFANT_ALIVE_AT_REPORT=0, BIRTH_PLACE='1', MOTHER_AGE_YEARS=12, FATHER_COMBINED_AGE=99, CIG_BEFORE=0, CIG_1_TRI=0, CIG_2_TRI=0, CIG_3_TRI=0, MOTHER_HEIGHT_IN=62, MOTHER_PRE_WEIGHT=145, MOTHER_DELIVERY_WEIGHT=152, MOTHER_WEIGHT_GAIN=7, DIABETES_PRE=0, DIABETES_GEST=0, HYP_TENS_PRE=0, HYP_TENS_GEST=0, INFANT_WEIGHT_GRAMS=0, BIRTH_PLACE_INT=1, BIRTH_PALCE_VEC=SparseVector(9, {1: 1.0}), features=SparseVector(24, {0: 12.0, 1: 99.0, 6: 62.0, 7: 145.0, 8: 152.0, 9: 7.0, 16: 1.0}), rawPrediction=DenseVector([0.9458, -0.9458]), probability=DenseVector([0.7203, 0.2797]), prediction=0.0)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.evaluation as ev\n",
    "evaluator = ev.BinaryClassificationEvaluator(rawPredictionCol='probability', labelCol='INFANT_ALIVE_AT_REPORT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7434490669849834\n",
      "0.7201551931757337\n"
     ]
    }
   ],
   "source": [
    "print(evaluator.evaluate(test_model, {evaluator.metricName:'areaUnderROC'}))\n",
    "print(evaluator.evaluate(test_model, {evaluator.metricName:'areaUnderPR'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelinePath = './infant_oneHotEncoder_logistic_pipeline'\n",
    "pipeline.write().overwrite().save(pipelinePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(INFANT_ALIVE_AT_REPORT=0, BIRTH_PLACE='1', MOTHER_AGE_YEARS=12, FATHER_COMBINED_AGE=99, CIG_BEFORE=0, CIG_1_TRI=0, CIG_2_TRI=0, CIG_3_TRI=0, MOTHER_HEIGHT_IN=62, MOTHER_PRE_WEIGHT=145, MOTHER_DELIVERY_WEIGHT=152, MOTHER_WEIGHT_GAIN=7, DIABETES_PRE=0, DIABETES_GEST=0, HYP_TENS_PRE=0, HYP_TENS_GEST=0, INFANT_WEIGHT_GRAMS=0, BIRTH_PLACE_INT=1, BIRTH_PALCE_VEC=SparseVector(9, {1: 1.0}), features=SparseVector(24, {0: 12.0, 1: 99.0, 6: 62.0, 7: 145.0, 8: 152.0, 9: 7.0, 16: 1.0}), rawPrediction=DenseVector([0.9458, -0.9458]), probability=DenseVector([0.7203, 0.2797]), prediction=0.0)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadedPipeline = Pipeline.load(pipelinePath)\n",
    "loadedPipeline.fit(births_train).transform(births_test).take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "modelPath = './infant_oneHotEncoder_logistic_pipelineModel'\n",
    "model.write().overwrite().save(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[INFANT_ALIVE_AT_REPORT: int, BIRTH_PLACE: string, MOTHER_AGE_YEARS: int, FATHER_COMBINED_AGE: int, CIG_BEFORE: int, CIG_1_TRI: int, CIG_2_TRI: int, CIG_3_TRI: int, MOTHER_HEIGHT_IN: int, MOTHER_PRE_WEIGHT: int, MOTHER_DELIVERY_WEIGHT: int, MOTHER_WEIGHT_GAIN: int, DIABETES_PRE: int, DIABETES_GEST: int, HYP_TENS_PRE: int, HYP_TENS_GEST: int, INFANT_WEIGHT_GRAMS: int, BIRTH_PLACE_INT: int, BIRTH_PALCE_VEC: vector, features: vector, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadedPipelineModel = PipelineModel.load(modelPath)\n",
    "test_loadedModel = loadedPipelineModel.transform(births_test)\n",
    "test_loadedModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Hyper-tuning\n",
    "Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.tuning as tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = cl.LogisticRegression(labelCol='INFANT_ALIVE_AT_REPORT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = tune.ParamGridBuilder().addGrid(logistic.maxIter,[2,10,50]\n",
    "                              ).addGrid(logistic.regParam, [0.01,0.05,0.3]\n",
    "                               ).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ev.BinaryClassificationEvaluator(rawPredictionCol='probability', labelCol='INFANT_ALIVE_AT_REPORT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = tune.CrossValidator(estimator=logistic, estimatorParamMaps=grid, evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[encoder, featuresCreator])\n",
    "data_transformer = pipeline.fit(births_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel = cv.fit(data_transformer.transform(births_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_transformer.transform(births_test)\n",
    "results = cvModel.transform(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[INFANT_ALIVE_AT_REPORT: int, BIRTH_PLACE: string, MOTHER_AGE_YEARS: int, FATHER_COMBINED_AGE: int, CIG_BEFORE: int, CIG_1_TRI: int, CIG_2_TRI: int, CIG_3_TRI: int, MOTHER_HEIGHT_IN: int, MOTHER_PRE_WEIGHT: int, MOTHER_DELIVERY_WEIGHT: int, MOTHER_WEIGHT_GAIN: int, DIABETES_PRE: int, DIABETES_GEST: int, HYP_TENS_PRE: int, HYP_TENS_GEST: int, INFANT_WEIGHT_GRAMS: int, BIRTH_PLACE_INT: int, BIRTH_PALCE_VEC: vector, features: vector, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7441328157027877\n",
      "0.7212737531230229\n"
     ]
    }
   ],
   "source": [
    "print(evaluator.evaluate(results, {evaluator.metricName:'areaUnderROC'}))\n",
    "print(evaluator.evaluate(results, {evaluator.metricName:'areaUnderPR'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [([{key.name: paramValue} for key, paramValue in zip(params.keys(), params.values())], \n",
    "            metric) for params, metric in zip(cvModel.getEstimatorParamMaps(), cvModel.avgMetrics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([{'maxIter': 50}, {'regParam': 0.01}], 0.7370975222895131),\n",
       " ([{'maxIter': 50}, {'regParam': 0.05}], 0.7319692995491217),\n",
       " ([{'maxIter': 10}, {'regParam': 0.01}], 0.7318310325069776),\n",
       " ([{'maxIter': 10}, {'regParam': 0.05}], 0.7283675067258283),\n",
       " ([{'maxIter': 10}, {'regParam': 0.3}], 0.7215628129975982),\n",
       " ([{'maxIter': 50}, {'regParam': 0.3}], 0.7183894610136353),\n",
       " ([{'maxIter': 2}, {'regParam': 0.3}], 0.6958649711790963),\n",
       " ([{'maxIter': 2}, {'regParam': 0.05}], 0.6951038391305423),\n",
       " ([{'maxIter': 2}, {'regParam': 0.01}], 0.6949743233092479)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(results, key=lambda el: el[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = ft.ChiSqSelector(numTopFeatures=5,\n",
    "                           featuresCol=featuresCreator.getOutputCol(),\n",
    "                           outputCol='selectedFeatures',\n",
    "                           labelCol='INFANT_ALIVE_AT_REPORT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = cl.LogisticRegression(labelCol='INFANT_ALIVE_AT_REPORT',\n",
    "                                featuresCol='selectedFeatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[encoder, featuresCreator, selector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformer = pipeline.fit(births_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvs = tune.TrainValidationSplit(estimator=logistic, estimatorParamMaps=grid, evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvsModel = tvs.fit(data_transformer.transform(births_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_transformer.transform(births_test)\n",
    "results = tvsModel.transform(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.735357446903953\n",
      "0.7148733525428738\n"
     ]
    }
   ],
   "source": [
    "print(evaluator.evaluate(results, {evaluator.metricName:'areaUnderROC'}))\n",
    "print(evaluator.evaluate(results, {evaluator.metricName:'areaUnderPR'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준화 작업\n",
    "import numpy as np\n",
    "x = np.arange(0,100)\n",
    "x = x / 100.0 * np.pi * 4\n",
    "y = x * np.sin(x / 1.764) + 20.1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = typ.StructType([\n",
    "    typ.StructField('continuous_var', typ.DoubleType(), False)\n",
    "])\n",
    "data = spark.createDataFrame([[float(e),] for e in y], schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|    continuous_var|\n",
      "+------------------+\n",
      "|           20.1234|\n",
      "|20.132344452369832|\n",
      "|20.159087064491775|\n",
      "|20.203356291885854|\n",
      "| 20.26470185735763|\n",
      "|20.342498180090526|\n",
      "|  20.4359491438498|\n",
      "|20.544094172020312|\n",
      "|20.665815568330437|\n",
      "|20.799847073505322|\n",
      "|  20.9447835797997|\n",
      "| 21.09909193743627|\n",
      "|21.261122779470593|\n",
      "| 21.42912328456607|\n",
      "| 21.60125079063745|\n",
      "|21.775587166351258|\n",
      "|21.950153842094366|\n",
      "|22.122927397273514|\n",
      "|22.291855596719525|\n",
      "|22.454873765567744|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = ft.VectorAssembler(inputCols=['continuous_var'], outputCol='continuous_vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = ft.StandardScaler(inputCol=vectorizer.getOutputCol(),\n",
    "                              outputCol='normalized',\n",
    "                              withMean=True,\n",
    "                              withStd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[vectorizer, normalizer])\n",
    "data_standardized = pipeline.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+--------------------+\n",
      "|    continuous_var|      continuous_vec|          normalized|\n",
      "+------------------+--------------------+--------------------+\n",
      "|           20.1234|           [20.1234]|[0.2342913955450239]|\n",
      "|20.132344452369832|[20.132344452369832]|[0.23630959828688...|\n",
      "|20.159087064491775|[20.159087064491775]|[0.24234373105178...|\n",
      "|20.203356291885854|[20.203356291885854]|[0.2523325232564438]|\n",
      "| 20.26470185735763| [20.26470185735763]|[0.2661743755372571]|\n",
      "|20.342498180090526|[20.342498180090526]|[0.28372813348174...|\n",
      "|  20.4359491438498|  [20.4359491438498]|[0.3048141635135427]|\n",
      "|20.544094172020312|[20.544094172020312]|[0.32921572364798...|\n",
      "|20.665815568330437|[20.665815568330437]|[0.3566806198337408]|\n",
      "|20.799847073505322|[20.799847073505322]|[0.38692313665363...|\n",
      "|  20.9447835797997|  [20.9447835797997]|[0.41962622928625...|\n",
      "| 21.09909193743627| [21.09909193743627]|[0.45444396184237...|\n",
      "|21.261122779470593|[21.261122779470593]|[0.49100417549639...|\n",
      "| 21.42912328456607| [21.42912328456607]|[0.5289113682453717]|\n",
      "| 21.60125079063745| [21.60125079063745]|[0.5677497666557837]|\n",
      "|21.775587166351258|[21.775587166351258]| [0.607086568611145]|\n",
      "|21.950153842094366|[21.950153842094366]|[0.6464753348602794]|\n",
      "|22.122927397273514|[22.122927397273514]|[0.6854595060946456]|\n",
      "|22.291855596719525|[22.291855596719525]|[0.7235760213604682]|\n",
      "|22.454873765567744|[22.454873765567744]|[0.7603590128437547]|\n",
      "+------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_standardized.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
