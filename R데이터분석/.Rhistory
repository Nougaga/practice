data <- fromJSON(RAWDATA)
# 작성일을 data 구조로 변경
data$items$postdate2 <- as.Date(data$items[,"postdate"],format="%Y%m%d")
# 글 제목에 들어있는 키워드 수
data$items$cnt_kw_t <- str_count(data$items[,"title"], pattern="<b>")
# 글 제목에 들어있는 키워드 수
data$items$cnt_kw_t <- str_count(data$items[,"title"], pattern="<b>")
# 글 제목에 들어있는 키워드 수
data$items$cnt_kw_t <- str_count(data$items[,"title"], pattern="<b>")
data$items
data$items
View(data$items)
data <- fromJSON(RAWDATA)
data
i=2
temp <- get_blogData(ONEPIECE, i, JSON)
temp
temp <- glaemfdj(blogData_onepiece, ONEPIECE)
RAWDATA <- temp
PATTERN <- ONEPIECE
data <- fromJSON(RAWDATA)
data
# 작성일을 data 구조로 변경
data$items$postdate2 <- as.Date(data$items[,"postdate"],format="%Y%m%d")
# 글 제목에 들어있는 키워드 수
data$items$cnt_kw_t <- str_count(data$items[,"title"], pattern="<b>")
# 글 본문 요약에 들어있는 키워드 수
data$items$cnt_kw_d <- str_count(data$items[,"description"], pattern="<b>")
# 검색기준일을 data 구조로 변경
temp <- strsplit(data[["lastBuildDate"]]," ")
temp <- unlist(temp)
temp[1] <- gsub(",","",temp[1])
temp <- paste(temp[2], tf_month(temp[3]), temp[4])
data[["lastBuildDate2"]] <- as.Date(temp, "%d %m %Y")
rm(temp)
# 본문 스크래핑
for (i in 1:100){
test_gsub <- data$items[i,"link"]
test_gsub <- gsub("https://blog.naver.com/","",test_gsub)
test_gsub <- gsub("[?]","=",test_gsub)
test_gsub <- strsplit(test_gsub, "=")
test_gsub <- unlist(test_gsub)
blogId <- test_gsub[1]; logNo <- test_gsub[4]
rm(test_gsub)
url_test <- paste("https://blog.naver.com/PostView.nhn?blogId=",blogId,"&logNo=",logNo,"&redirect=Dlog&widgetTypeCall=true&directAccess=false",sep="")
# html 코드 전부
html_test <- read_html(url_test, options = "HUGE")
# pc/mobile, editer ver.에 따라 container가 다름
html_main <- html_test %>% html_node("div.se-main-container")
if (length(html_main)==0){
html_main <- html_test %>% html_node("div.se_component_wrap.sect_dsc.__se_component_area")
}
if (length(html_main)==0){
html_main <- html_test %>% html_node("div#postViewArea")
}
data$items$cnt_kw_m[i] <- str_count(html_main, pattern=PATTERN)
data$items$cnt_href_m[i] <- str_count(html_main, pattern="<a href=\"http")
# 본문 내용
vec_text <- html_main %>% html_nodes("p") %>% html_text()
vec_text <- vec_text[vec_text!=OBSTACLE1]
chr_text <- paste(vec_text, collapse=" ")
chr_text <- gsub("[[:space:]]{2,}","",chr_text)
# chr_text300 <- chr_text
# Encoding(chr_text300) <- "bytes"
# chr_text300 <- substr(chr_text300, 1, 300)
# Encoding(chr_text300) <- "UTF-8"
# data$items$cnt_kw_m300[i] <- str_count(chr_text300, pattern=PATTERN)
vec_text_grep <- grep(PATTERN, vec_text)
data$items$idx_p_m[i] <- vec_text_grep[1]
data$items$cnt_p_m[i] <- length(vec_text_grep)
data$items$emo_w_m[i] <- str_count(chr_text,"[?^]{2}") + str_count(chr_text, "ㅎㅎ")
vec_img <- html_main %>% html_nodes("img") %>% html_attr("src")
chr_img <- paste(vec_img, collapse=" ")
data$items$emo_LINE_m[i] <-
str_count(chr_img, LINE_STICKER1) +
str_count(chr_img, LINE_STICKER2) +
str_count(chr_img, LINE_STICKER3) +
str_count(chr_img, LINE_STICKER4) +
str_count(chr_img, LINE_STICKER5) +
str_count(chr_img, LINE_STICKER6)
}
data$items$daysdiff <- as.numeric(data$lastBuildDate2 - data$items$postdate2)
View(data$items)
# 유의미할 것 같은 데이터로 변환하는 func
glaemfdj <- function(RAWDATA, PATTERN){
# (kw: keyword, t: title, d: description, m: main-container, p: paragraph, w: word)
# postdate2   작성일(날짜 형식으로 변환됨)
# cnt_kw_t    글 제목에서 키워드 수
# cnt_kw_d    글 요약에서 키워드 수
# cnt_kw_m    글 본문에서 키워드 수
# cnt_href_m  글 본문에서 외부 링크 수
# cnt_kw_m300 글 본문의 처음 300bytes(글 요약 후보)에서 키워드 수
# idx_p_m     글 본문에서 키워드가 처음 등장한 문단 위치
# cnt_p_m     글 본문에서 키워드가 등장한 문단 수
# emo_w_m     글 본문에서 ^^, ㅎㅎ 수
# emo_LINE_m  글 본문에서 LINE 스티커 수
# daysdiff    검색일과 작성일 차이
data <- fromJSON(RAWDATA)
# 작성일을 data 구조로 변경
data$items$postdate2 <- as.Date(data$items[,"postdate"],format="%Y%m%d")
# 글 제목에 들어있는 키워드 수
data$items$cnt_kw_t <- str_count(data$items[,"title"], pattern="<b>")
# 글 본문 요약에 들어있는 키워드 수
data$items$cnt_kw_d <- str_count(data$items[,"description"], pattern="<b>")
# 검색기준일을 data 구조로 변경
temp <- strsplit(data[["lastBuildDate"]]," ")
temp <- unlist(temp)
temp[1] <- gsub(",","",temp[1])
temp <- paste(temp[2], tf_month(temp[3]), temp[4])
data[["lastBuildDate2"]] <- as.Date(temp, "%d %m %Y")
rm(temp)
# 본문 스크래핑
for (i in 1:100){
test_gsub <- data$items[i,"link"]
test_gsub <- gsub("https://blog.naver.com/","",test_gsub)
test_gsub <- gsub("[?]","=",test_gsub)
test_gsub <- strsplit(test_gsub, "=")
test_gsub <- unlist(test_gsub)
blogId <- test_gsub[1]; logNo <- test_gsub[4]
rm(test_gsub)
url_test <- paste("https://blog.naver.com/PostView.nhn?blogId=",blogId,"&logNo=",logNo,"&redirect=Dlog&widgetTypeCall=true&directAccess=false",sep="")
# html 코드 전부
html_test <- read_html(url_test, options = "HUGE")
# pc/mobile, editer ver.에 따라 container가 다름
html_main <- html_test %>% html_node("div.se-main-container")
if (length(html_main)==0){
html_main <- html_test %>% html_node("div.se_component_wrap.sect_dsc.__se_component_area")
}
if (length(html_main)==0){
html_main <- html_test %>% html_node("div#postViewArea")
}
data$items$cnt_kw_m[i] <- str_count(html_main, pattern=PATTERN)
data$items$cnt_href_m[i] <- str_count(html_main, pattern="<a href=\"http")
# 본문 내용
vec_text <- html_main %>% html_nodes("p") %>% html_text()
vec_text <- vec_text[vec_text!=OBSTACLE1]
chr_text <- paste(vec_text, collapse=" ")
chr_text <- gsub("[[:space:]]{2,}","",chr_text)
# chr_text300 <- chr_text
# Encoding(chr_text300) <- "bytes"
# chr_text300 <- substr(chr_text300, 1, 300)
# Encoding(chr_text300) <- "UTF-8"
# data$items$cnt_kw_m300[i] <- str_count(chr_text300, pattern=PATTERN)
vec_text_grep <- grep(PATTERN, vec_text)
data$items$idx_p_m[i] <- vec_text_grep[1]
data$items$cnt_p_m[i] <- length(vec_text_grep)
data$items$emo_w_m[i] <- str_count(chr_text,"[?^]{2}") + str_count(chr_text, "ㅎㅎ")
vec_img <- html_main %>% html_nodes("img") %>% html_attr("src")
chr_img <- paste(vec_img, collapse=" ")
data$items$emo_LINE_m[i] <-
str_count(chr_img, LINE_STICKER1) +
str_count(chr_img, LINE_STICKER2) +
str_count(chr_img, LINE_STICKER3) +
str_count(chr_img, LINE_STICKER4) +
str_count(chr_img, LINE_STICKER5) +
str_count(chr_img, LINE_STICKER6)
}
data$items$daysdiff <- as.numeric(data$lastBuildDate2 - data$items$postdate2)
return(data)
}
for (i in 2:10){
rest <- get_blogData(ONEPIECE, i, JSON)
rest <- glaemfdj(rest, ONEPIECE)
blogdata_onepiece$items <- rbind(blogdata_onepiece$items, temp$items)
}
blogData_onepiece <- get_blogData(ONEPIECE, 1, JSON)
blogData_onepiece <- glaemfdj(blogData_onepiece, ONEPIECE)
for (i in 2:10){
rest <- get_blogData(ONEPIECE, i, JSON)
rest <- glaemfdj(rest, ONEPIECE)
blogdata_onepiece$items <- rbind(blogdata_onepiece$items, temp$items)
}
blogdata_onepiece$items <- rbind(blogData_onepiece$items, temp$items)
blogdata_onepiece$items <- rbind(blogData_onepiece$items, rest$items)
blogData_onepiece$items <- rbind(blogData_onepiece$items, rest$items)
View(blogData_onepiece$items)
rm(rest)
blogData_onepiece <- get_blogData(ONEPIECE, 1, JSON)
blogData_onepiece <- glaemfdj(blogData_onepiece, ONEPIECE)
for (i in 2:10){
rest <- get_blogData(ONEPIECE, i, JSON)
rest <- glaemfdj(rest, ONEPIECE)
blogData_onepiece$items <- rbind(blogData_onepiece$items, rest$items)
}
rm(rest)
View(blogData_onepiece$items)
i=3
rest <- get_blogData(ONEPIECE, i, JSON)
# cnt_kw_t    글 제목에서 키워드 수
# cnt_kw_d    글 요약에서 키워드 수
# cnt_kw_m    글 본문에서 키워드 수
# cnt_href_m  글 본문에서 외부 링크 수
# cnt_kw_m300 글 본문의 처음 300bytes(글 요약 후보)에서 키워드 수
# idx_p_m     글 본문에서 키워드가 처음 등장한 문단 위치
# cnt_p_m     글 본문에서 키워드가 등장한 문단 수
# emo_w_m     글 본문에서 ^^, ㅎㅎ 수
# emo_LINE_m  글 본문에서 LINE 스티커 수
# daysdiff    검색일과 작성일 차이
RAWDATA <- rest; PATTERN <- ONEPIECE
# cnt_kw_t    글 제목에서 키워드 수
# cnt_kw_d    글 요약에서 키워드 수
# cnt_kw_m    글 본문에서 키워드 수
# cnt_href_m  글 본문에서 외부 링크 수
# cnt_kw_m300 글 본문의 처음 300bytes(글 요약 후보)에서 키워드 수
# idx_p_m     글 본문에서 키워드가 처음 등장한 문단 위치
# cnt_p_m     글 본문에서 키워드가 등장한 문단 수
# emo_w_m     글 본문에서 ^^, ㅎㅎ 수
# emo_LINE_m  글 본문에서 LINE 스티커 수
# daysdiff    검색일과 작성일 차이
RAWDATA <- rest; PATTERN <- ONEPIECE
data <- fromJSON(RAWDATA)
# 작성일을 data 구조로 변경
data$items$postdate2 <- as.Date(data$items[,"postdate"],format="%Y%m%d")
# 글 제목에 들어있는 키워드 수
data$items$cnt_kw_t <- str_count(data$items[,"title"], pattern="<b>")
# 글 본문 요약에 들어있는 키워드 수
data$items$cnt_kw_d <- str_count(data$items[,"description"], pattern="<b>")
# 검색기준일을 data 구조로 변경
temp <- strsplit(data[["lastBuildDate"]]," ")
temp <- unlist(temp)
temp[1] <- gsub(",","",temp[1])
temp <- paste(temp[2], tf_month(temp[3]), temp[4])
data[["lastBuildDate2"]] <- as.Date(temp, "%d %m %Y")
rm(temp)
# 본문 스크래핑
for (i in 1:100){
test_gsub <- data$items[i,"link"]
test_gsub <- gsub("https://blog.naver.com/","",test_gsub)
test_gsub <- gsub("[?]","=",test_gsub)
test_gsub <- strsplit(test_gsub, "=")
test_gsub <- unlist(test_gsub)
blogId <- test_gsub[1]; logNo <- test_gsub[4]
rm(test_gsub)
url_test <- paste("https://blog.naver.com/PostView.nhn?blogId=",blogId,"&logNo=",logNo,"&redirect=Dlog&widgetTypeCall=true&directAccess=false",sep="")
# html 코드 전부
html_test <- read_html(url_test, options = "HUGE")
# pc/mobile, editer ver.에 따라 container가 다름
html_main <- html_test %>% html_node("div.se-main-container")
if (length(html_main)==0){
html_main <- html_test %>% html_node("div.se_component_wrap.sect_dsc.__se_component_area")
}
if (length(html_main)==0){
html_main <- html_test %>% html_node("div#postViewArea")
}
data$items$cnt_kw_m[i] <- str_count(html_main, pattern=PATTERN)
data$items$cnt_href_m[i] <- str_count(html_main, pattern="<a href=\"http")
# 본문 내용
vec_text <- html_main %>% html_nodes("p") %>% html_text()
vec_text <- vec_text[vec_text!=OBSTACLE1]
chr_text <- paste(vec_text, collapse=" ")
chr_text <- gsub("[[:space:]]{2,}","",chr_text)
# chr_text300 <- chr_text
# Encoding(chr_text300) <- "bytes"
# chr_text300 <- substr(chr_text300, 1, 300)
# Encoding(chr_text300) <- "UTF-8"
# data$items$cnt_kw_m300[i] <- str_count(chr_text300, pattern=PATTERN)
vec_text_grep <- grep(PATTERN, vec_text)
data$items$idx_p_m[i] <- vec_text_grep[1]
data$items$cnt_p_m[i] <- length(vec_text_grep)
data$items$emo_w_m[i] <- str_count(chr_text,"[?^]{2}") + str_count(chr_text, "ㅎㅎ")
vec_img <- html_main %>% html_nodes("img") %>% html_attr("src")
chr_img <- paste(vec_img, collapse=" ")
data$items$emo_LINE_m[i] <-
str_count(chr_img, LINE_STICKER1) +
str_count(chr_img, LINE_STICKER2) +
str_count(chr_img, LINE_STICKER3) +
str_count(chr_img, LINE_STICKER4) +
str_count(chr_img, LINE_STICKER5) +
str_count(chr_img, LINE_STICKER6)
}
View(data$items)
i=44
test_gsub <- data$items[i,"link"]
test_gsub
# 유의미할 것 같은 데이터로 변환하는 func
glaemfdj <- function(RAWDATA, PATTERN){
# (kw: keyword, t: title, d: description, m: main-container, p: paragraph, w: word)
# postdate2   작성일(날짜 형식으로 변환됨)
# cnt_kw_t    글 제목에서 키워드 수
# cnt_kw_d    글 요약에서 키워드 수
# cnt_kw_m    글 본문에서 키워드 수
# cnt_href_m  글 본문에서 외부 링크 수
# cnt_kw_m300 글 본문의 처음 300bytes(글 요약 후보)에서 키워드 수
# idx_p_m     글 본문에서 키워드가 처음 등장한 문단 위치
# cnt_p_m     글 본문에서 키워드가 등장한 문단 수
# emo_w_m     글 본문에서 ^^, ㅎㅎ 수
# emo_LINE_m  글 본문에서 LINE 스티커 수
# daysdiff    검색일과 작성일 차이
data <- fromJSON(RAWDATA)
# 작성일을 data 구조로 변경
data$items$postdate2 <- as.Date(data$items[,"postdate"],format="%Y%m%d")
# 글 제목에 들어있는 키워드 수
data$items$cnt_kw_t <- str_count(data$items[,"title"], pattern="<b>")
# 글 본문 요약에 들어있는 키워드 수
data$items$cnt_kw_d <- str_count(data$items[,"description"], pattern="<b>")
# 검색기준일을 data 구조로 변경
temp <- strsplit(data[["lastBuildDate"]]," ")
temp <- unlist(temp)
temp[1] <- gsub(",","",temp[1])
temp <- paste(temp[2], tf_month(temp[3]), temp[4])
data[["lastBuildDate2"]] <- as.Date(temp, "%d %m %Y")
rm(temp)
# 본문 스크래핑
for (i in 1:100){
test_gsub <- data$items[i,"link"]
if (!grepl("https://blog.naver.com",test_gsub)){
next
}
test_gsub <- gsub("https://blog.naver.com/","",test_gsub)
test_gsub <- gsub("[?]","=",test_gsub)
test_gsub <- strsplit(test_gsub, "=")
test_gsub <- unlist(test_gsub)
blogId <- test_gsub[1]; logNo <- test_gsub[4]
rm(test_gsub)
url_test <- paste("https://blog.naver.com/PostView.nhn?blogId=",blogId,"&logNo=",logNo,"&redirect=Dlog&widgetTypeCall=true&directAccess=false",sep="")
# html 코드 전부
html_test <- read_html(url_test, options = "HUGE")
# pc/mobile, editer ver.에 따라 container가 다름
html_main <- html_test %>% html_node("div.se-main-container")
if (length(html_main)==0){
html_main <- html_test %>% html_node("div.se_component_wrap.sect_dsc.__se_component_area")
}
if (length(html_main)==0){
html_main <- html_test %>% html_node("div#postViewArea")
}
data$items$cnt_kw_m[i] <- str_count(html_main, pattern=PATTERN)
data$items$cnt_href_m[i] <- str_count(html_main, pattern="<a href=\"http")
# 본문 내용
vec_text <- html_main %>% html_nodes("p") %>% html_text()
vec_text <- vec_text[vec_text!=OBSTACLE1]
chr_text <- paste(vec_text, collapse=" ")
chr_text <- gsub("[[:space:]]{2,}","",chr_text)
# chr_text300 <- chr_text
# Encoding(chr_text300) <- "bytes"
# chr_text300 <- substr(chr_text300, 1, 300)
# Encoding(chr_text300) <- "UTF-8"
# data$items$cnt_kw_m300[i] <- str_count(chr_text300, pattern=PATTERN)
vec_text_grep <- grep(PATTERN, vec_text)
data$items$idx_p_m[i] <- vec_text_grep[1]
data$items$cnt_p_m[i] <- length(vec_text_grep)
data$items$emo_w_m[i] <- str_count(chr_text,"[?^]{2}") + str_count(chr_text, "ㅎㅎ")
vec_img <- html_main %>% html_nodes("img") %>% html_attr("src")
chr_img <- paste(vec_img, collapse=" ")
data$items$emo_LINE_m[i] <-
str_count(chr_img, LINE_STICKER1) +
str_count(chr_img, LINE_STICKER2) +
str_count(chr_img, LINE_STICKER3) +
str_count(chr_img, LINE_STICKER4) +
str_count(chr_img, LINE_STICKER5) +
str_count(chr_img, LINE_STICKER6)
}
data$items$daysdiff <- as.numeric(data$lastBuildDate2 - data$items$postdate2)
return(data)
}
blogData_onepiece$items <- rbind(blogData_onepiece$items, rest$items)
View(blogData_onepiece$items)
rest
rest <- glaemfdj(rest, ONEPIECE)
blogData_onepiece$items <- rbind(blogData_onepiece$items, rest$items)
blogData_onepiece <- get_blogData(ONEPIECE, 1, JSON)
blogData_onepiece <- glaemfdj(blogData_onepiece, ONEPIECE)
for (idx in 2:10){
cat("get_blogData(ONEPIECE, ",idx,", JSON)\n",sep="")
rest <- get_blogData(ONEPIECE, idx, JSON)
cat("glaemfdj(rest, ONEPIECE)\n", sep="")
rest <- glaemfdj(rest, ONEPIECE)
cat("rbind(blogData_onepiece$items, rest$items)\n",sep="")
blogData_onepiece$items <- rbind(blogData_onepiece$items, rest$items)
}
View(blogData_onepiece$items)
length(blogData_onepiece$items$title)
blogData_onepiece$items$score <- (1+blogData_onepiece$total-1:length(blogData_onepiece$items$title))/blogData_onepiece$total
View(blogData_onepiece$items)
testtest <- blogData_onepiece$items[grepl("https://blog.naver.com",blogData_onepiece$items$bloggerlink),]
View(testtest)
length(blogData_onepiece$items$bloggerlink)
length(testtest)
length(testtest$title)
summary(testtest)
testtest <- testtest[!is.na(testtest$idx_p_m),]
summary(testtest)
blogData_onepiece$items <- testtest
View(testtest)
View(testtest)
testtest <- blogData_onepiece$items[,8:17]
library(Hmisc); library(corrgram)
corrgram::corrgram(as.matrix(testtest), upper.panel = panel.conf)
test_lm <- lm(score~., data=testtest)
summary(test_lm)
View(pwcList_engineer)
cntTable <- table(pwcList_onepiece$bloggerlink)
cntTable
cntTable <- table(pwcList_engineer$bloggerlink)
cntTable
cntTable_onepiece <- table(pwcList_onepiece$bloggerlink)
cntTable_smartphone <- table(pwcList_smartphone$bloggerlink)
cntTable_toeicspeaking <- table(pwcList_toeicspeaking$bloggerlink)
cntTable_engineer <- table(pwcList_engineer$bloggerlink)
cntTable_engineer["http://blog.naver.com/dwittt"]
cntTable_engineer["ht"]
View(blogData_onepiece)
View(blogData_onepiece)
test2 <- blogData_onepiece
blogData_onepiece$items$bloggerlink
cntTable_engineer[blogData_onepiece$items$bloggerlink]
cntTable_onepiece[blogData_onepiece$items$bloggerlink]
cntTable_engineer["http://blog.naver.com/eduwill_love"]
cntTable_engineer[c("http://blog.naver.com/eduwill_love", "http://blog.naver.com/eduwill_love")]
cntTable_engineer[c("http://blog.naver.com/eduwill_love", "http://blog.naver.com/eduwill_love")][1]
cntTable_engineer[c("http://blog.naver.com/eduwill_love", "http://blog.naver.com/giveapeck")][1]
cntTable_engineer[c("http://blog.naver.com/eduwill_love", "http://blog.naver.com/giveapeck")][1,2]
cntTable_engineer[c("http://blog.naver.com/eduwill_love", "http://blog.naver.com/giveapeck")][2]
as.numeric(cntTable_engineer[c("http://blog.naver.com/eduwill_love", "http://blog.naver.com/giveapeck")][2])
as.numeric(cntTable_onepiece[blogData_onepiece$items$bloggerlink])
blogData_onepiece$items$cnt_pwc <- as.numeric(cntTable_onepiece[blogData_onepiece$items$bloggerlink])
temp <- as.numeric(cntTable_onepiece[blogData_onepiece$items$bloggerlink])
temp[is.na(temp),] <- 0
temp[is.na(temp)] <- 0
temp
blogData_onepiece$items$cnt_pwc <- temp
rm(temp)
testtest <- blogData_onepiece$items[,8:18]
corrgram::corrgram(as.matrix(testtest), upper.panel = panel.conf)
temp <- as.numeric(cntTable_onepiece[blogData_onepiece$items$bloggerlink])
temp[is.na(temp)] <- 0
blogData_onepiece$items$cnt_pwc <- temp
corrgram::corrgram(as.matrix(testtest), upper.panel = panel.conf)
View(blogData_onepiece$items)
warnings()
test_lm <- lm(score~., data=testtest)
test_lm <- lm(score~., data=testtest)
summary(test_lm)
test_step <- step(a,
scope=list(lower=~-1, upper=~.),
direction = "backward")
test_step <- step(testtest,
scope=list(lower=~-1, upper=~.),
direction = "backward")
test_step <- step(testtest,
direction = "backward")
test_step <- step(test_lm,
direction = "backward")
?step
test_step <- step(test_lm,
direction = "both")
test_step <- step(test_lm, direction = "both")
corrgram::corrgram(as.matrix(testtest), upper.panel = panel.conf)
blogData_lm <- get_blogData(LM, 1, JSON)
blogData_lm <- glaemfdj(blogData_lm, LM)
for (idx in 2:10){
cat("get_blogData(LM, ",idx,", JSON)\n",sep="")
rest <- get_blogData(LM, idx, JSON)
cat("glaemfdj(rest, LM)\n", sep="")
rest <- glaemfdj(rest, LM)
cat("rbind(blogData_lm$items, rest$items)\n",sep="")
blogData_lm$items <- rbind(blogData_lm$items, rest$items)
}
blogData_lm$items$score <- (1+blogData_lm$total-1:length(blogData_lm$items$title))/blogData_lm$total
testtest <- blogData_lm$items[grepl("https://blog.naver.com",blogData_lm$items$bloggerlink),]
testtest <- testtest[!is.na(testtest$idx_p_m),]
blogData_lm$items <- testtest
View(blogData_lm$items)
testData_lm <- blogData_lm$items[,8:18]
testData_lm <- blogData_lm$items[,8:18]
testData_lm <- blogData_lm$items[,8:17]
corrgram::corrgram(as.matrix(testData_lm), upper.panel = panel.conf)
test_lm <- lm(score~., data=testData_lm)
summary(test_lm)
test_step <- step(test_lm, direction = "both")
summary(test_lm)
test_lm <- lm(score~., data=testtest)
test_lm <- lm(score~., data=testtest)
summary(test_lm)
testtest <- blogData_onepiece$items[,8:18]
corrgram::corrgram(as.matrix(testtest), upper.panel = panel.conf)
test_lm <- lm(score~., data=testtest)
summary(test_lm)
summary(lm(score~idx_p_m, data=testtest))
summary(lm(score~idx_p_m, data=testData_lm))
x,y <- 1,2
get_blogDataSet <- function(KEYWORD){
blogData <- get_blogData(KEYWORD, 1, JSON)
blogData <- glaemfdj(blogData, KEYWORD)
for (idx in 2:10){
cat(idx,"API 요청\n")
rest <- get_blogData(KEYWORD, idx, JSON)
cat(idx,"데이터 분석\n")
rest <- glaemfdj(rest, KEYWORD)
blogData$items <- rbind(blogData$items, rest$items)
}
blogData$items$score <- (1+blogData$total-1:length(blogData$items$title))/blogData$total
testtest <- blogData$items[grepl("https://blog.naver.com",blogData$items$bloggerlink),]
testtest <- testtest[!is.na(testtest$idx_p_m),]
blogData$items <- testtest
return(blogData)
}
blogData_toeicspeaking <- get_blogDataSet(TOEICSPEAKING)
View(blogData_toeicspeaking)
View(blogData_toeicspeaking)
testtest <- blogData_toeicspeaking$items[,8:17]
corrgram::corrgram(as.matrix(testtest), upper.panel = panel.conf)
test_lm <- lm(score~., data=testtest)
summary(test_lm)
test_step <- step(test_lm, direction = "both")
data(iris)
testdata <- iris
head(testdata)
testdata %>%
group_by(Species)
testdata %>%
group_by(Species) %>%
summarise(sepallength=mean(Sepal.Length))
