?cor
plot(drat, disp)
# 상관성 분석2
library(dlpyr)
# 상관성 분석2
library(dplyr)
mtcars %>% head
mtcars %>% str
mtcars %>% head
Hmisc::rcorr(as.matrix(mtcars), type="pearson")
install.packages("acepack")
library(acepack)
Hmisc::rcorr(as.matrix(mtcars), type="pearson")
# cf) 공분산
cov(mtcars)
# 'H0: 상관계수는 0이다'에 대한 p-value를 보여줌
Hmisc::rcorr(as.matrix(mtcars), type="pearson")
install.pacages("corrgram")
install.packages("corrgram")
library(corrgram)
install.packages("PerformanceAnalytics")
library(PerformanceAnalytics)
install.packages("PerformanceAnalytics")
install.packages("PerformanceAnalytics")
corrgram(as.matrix(mtcars), upper.panel = panel.conf)
chart.Correlation(as.matrix(mtcars))
par(mfrow=c(1,2))
par(mfrow=c(1,2))
library(PerformanceAnalytics)
chart.Correlation(as.matrix(mtcars))
par(mfrow=c(1,2))
corrgram(as.matrix(mtcars), upper.panel = panel.conf)
chart.Correlation(as.matrix(mtcars))
par(mfrow=c(1,2), type="s")
par(mfrow=c(1,2), pty="s")
par(mfrow=c(1,2), pty="s")
corrgram(as.matrix(mtcars), upper.panel = panel.conf)
chart.Correlation(as.matrix(mtcars))
corrgram::corrgram(as.matrix(mtcars), upper.panel = panel.conf)
PerformanceAnalytics::chart.Correlation(as.matrix(mtcars))
library(MASS)
# MASS 패키지의 닭 데이터
chicken <- ChickWeight
head(chicken)
head(chicken)
# 2) subsetting -> diet==1 & chick = 1
chick <- chicken %>% filter(Diet==1 & Chick==1) # 식이요법 1번을 적용한 닭
# 3) simple linear regression
chick.lm <- lm(formula = weight ~ Time, data=Chick)
# 3) simple linear regression
chick.lm <- lm(formula = weight ~ Time, data=chick)
head(chick.lm)
summary(chick.lm)
# 5) 결과 해석
plot(chick.lm)
# 6) 절편을 제거하는 회귀식
chick.nointer <- lm(formula=weight ~ -1 + Time, data=chick)
summary(chick.nointer)
product <- read.csv("..\\..\\..\\data\\product.csv", header=T)
str(product)
y <- product$제품_만족도    # 종속변수
x <- product$제품_적절성    # 독립변수
df <- data.frame(x,y)
y <- product$"제품_만족도"    # 종속변수
x <- product$"제품_적절성"    # 독립변수
df <- data.frame(x,y)
# 회귀모델 생성
result.lm <- lm(y~x, data=df)
result.lm
# 모델의 적합값과 잔차 보기
names(result.lm)
fitted.values(result.lm)
fitted.values(result.lm)[1:2]
head(df, 1)
head(df, 1)
Y = 0.7789 + 0.7393*4
Y
View(product)
View(product)
# 잔차(residual): 관측치 - 예측치
r = 3 - Y
# 잔차(residual): 관측치 - 예측치
(r = 3 - Y)
residuals(result.lm)
residuals(result.lm)[1:2]
# 잔차(residual): 관측치 - 예측치
(r = 3 - Y)
residuals(result.lm)[1:2]
# 선형회귀분석 모델 시각화, 오류 확인
# x, y 산점도 그리기
plot(formula=y~, data=df)
# 선형회귀분석 모델 시각화, 오류 확인
# x, y 산점도 그리기
plot(formula=y~x, data=df)
result.lm <- lm(formula=y~x, data=df)
plot(formula=y~x, data=df)
result.lm <- lm(formula=y~x, data=df)
abline(result.lm, col="red")
# 선형회귀분석 결과 보기
res <- summary(result.lm)
str(res)
str(res)
plot(res$residuals)
res <- summary(result.lm)
str(res)
plot(res$residuals)
y <- product$제품_만족도
x1 <- product$"제품_친밀도도"
y <- product$"제품_만족도"
y <- product$"제품_만족도"
x1 <- product$"제품_친밀도"
y <- product$"제품_만족도"
x1 <- product$"제품_친밀도"
x2 <- product$"제품_적절성"
df <- data.frame(x1,x2,y)
y <- product$"제품_만족도"
x1 <- product$"제품_친밀도"
x2 <- product$"제품_적절성"
df <- data.frame(x1,x2,y)
result.m <- lm(formula=y~x1+x2, data=df)
# 계수 확인
result.lm
summary(result.lm)
result.lm
summary(result.lm)
result.m <- lm(formula=y~x1+x2, data=df)
# 계수 확인
result.lm
summary(result.lm)
result.lm <- lm(formula=y~x1+x2, data=df)
# 계수 확인
result.lm
summary(result.lm)
library(car)
install.packages("car")
library(car)
vif(result.lm)
car::vif(result.lm)
sqrt(vif(result.lm)) > 2
# 분산팽창요인(VIF): 다중 공산성(독립변수들 간의 상관성) 문제 확인
car::vif(result.lm)# > 4이면 문제가 있다고 판단
rm(list=ls())
data(iris)
rm(ls())
#   1-2) 회귀모델 생성
model <- lm(formula= formula, data=iris)
# 1) 회귀모델 생성
#   1-1) 변수 모델링: y: Sepal.Length <- x: Sepal.Width, Petal.Length, Petal.Width
formula <- Sepal.Length ~ Sepal.Width + Petal.Length
#   1-2) 회귀모델 생성
model <- lm(formula=formula, data=iris)
model
summary(model)
# 2) 잔차[오차] 분석
#   2-1) 잔차 독립성 -> 더빈왓슨(자기상관성)
installpackages('lmtest')
# 2) 잔차[오차] 분석
#   2-1) 잔차 독립성 -> 더빈왓슨(자기상관성)
install.packages('lmtest')
library(lmtest)
#   2-2) 잔차도 확인 검정
par(mfrow=c(2,2))
lmtest::dwtest(model)
#   2-2) 잔차도 확인 검정
par(mfrow=c(2,2))
plot(model, which=1)  # 선형성(빨간 실선이 0에 가까운 수평선) & 독립성(특정한 모여있는 패턴이 발견되지 않음)
plot(model, which=2)  # 정규성(직선에 가깝게 잘 모여있음)
plot(model, which=3)  # 등분산성 & 독립성(적절하게 퍼져 있음, 특정 패턴 없음)
plot(model, which=4)  # 극단치
# 3) 잔차 정규성 검정
attributes(model)   # coefficients(계수), residuals(잔차), fitted.values(적합값)
model$residuals
shapiro.test(model$residuals) # 정규성 검정: p값 = 0.9349 > 0.05
# 3) 잔차 정규성 검정
attributes(model)   # coefficients(계수), residuals(잔차), fitted.values(적합값)
shapiro.test(model$residuals) # 정규성 검정: p값 = 0.7856 > 0.05
res <- residuals(model) # 잔차 추출출
# 정규성 시각화
head(res,20)
length(res)
res2 <- model$residuals
hist(res2, freq=F); lines(density(res2))
res2 <- model$residuals
shapiro.test(res2) # 정규성 검정: p값 = 0.7856 > 0.05
hist(res2, freq=F); lines(density(res2))
qqnorm(res2)
plot(model,2)
plot(model,2)
res
res2
res == res2
table(res==res2)
# 3) 잔차 정규성 검정
attributes(model)   # coefficients(계수), residuals(잔차), fitted.values(적합값)
res <- residuals(model) # 잔차 추출 res <- model$residuals
shapiro.test(res) # 정규성 검정: p값 = 0.7856 > 0.05
# 귀무가설: 정규성과 차이가 없다.
# 정규성 시각화
head(res,20)
length(res)
hist(res, freq=F); lines(density(res))
qqnorm(res)
plot(model,2)
x1 <- c(7,1,11,11,7,11,3,1,2,21,1,11,10)
x2 <- c(26,29,56,31,52,55,71,31,54,47,40,66,68)
x3 <- c(6,15,8,8,6,9,17,22,18,4,23,9,8)
x4 <- c(60,52,20,47,33,22,6,44,22,26,34,12,12)
y <- c(78.5,74.3,104.3,87.6,95.9,109.2,102.7,72.5,93.1,115.9,83.8,113.3,109.4)
df <- data.frame(x1,x2,x3,x4,y)
a1 <- lm(y~x1+x2+x4, data=df)
summary(a1)
a2 <- lm(y~x1+x2, data=df)
summary(a2)
aa <- step(a, scope=list(lower=~-, upper=~x1+x2+x3+x4))
aa <- step(a, scope=list(lower=~-1, upper=~x1+x2+x3+x4))
a <- lm(y~x1+x2+x3+x4, data=df)
summary(a)
aa <- step(a, scope=list(lower=~-1, upper=~x1+x2+x3+x4))
summary(aa)
aa <- step(a, scope=list(lower=~-1, upper=~x1+x2+x3+x4))
aa <- step(a,
scope=list(lower=~-1, upper=~x1+x2+x3+x4),
direction = "forward")
aa <- step(a,
scope=list(lower=~-1, upper=~x1+x2+x3+x4),
direction = "forward")
aa <- step(a,
scope=list(lower=~-1, upper=~x1+x2+x3+x4),
direction = "backward")
aa <- step(a,
scope=list(lower=~-1, upper=~x1+x2+x3+x4),
direction = "both")
aa <- step(a,
scope=list(lower=~-1, upper=~x1+x2+x3+x4),
direction = "forward")
aa <- step(a,
scope=list(lower=~-1, upper=~x1+x2+x3+x4),
direction = "backward")
library(mlbench)
data("BostonHousing")
?BostonHousing
?mlbench
bh <- BostonHousing
# 종속변수 medv:	median value of owner-occupied homes in USD 1000's
head(bh)
head(bh)
str(bh)
bh_step <- step(bh, scope=list(lower=~-1, upper=~x1+x2+x3+x4))
bh_step <- step(bh, scope=list(lower=~-1, upper=~crim+zn+indus+chas+nox+rm+age+dis+rad+tx+ptratio+b+lstat))
bh_step <- step(bh, scope=list(lower=~-1, upper=~bh$crim+bh$zn+bh$indus+bh$chas+bh$nox+bh$rm+bh$age+bh$dis+bh$rad+bh$tx+bh$ptratio+bh$b+bh$lstat))
bh_step <- step(bh, scope=list(lower=~-1, upper=~crim+zn))
bh <- BostonHousing
# 종속변수 medv:	median value of owner-occupied homes in USD 1000's
head(bh)
str(bh)
bh_step <- step(bh, scope=list(lower=~-1, upper=~crim+zn))
View(a)
View(a)
a
bh.lm <- lm(medv~crim+zn+indus+nox+rm+age+dis+rad+tax+ptratio+b+lstat, data=bh)
summary(bh.lm)
bh.step <- step(bh, scope=list(lower=~-1, upper=~crim+zn+indus+nox+rm+age+dis+rad+tax+ptratio+b+lstat))
bh.step <- step(bh.lm, scope=list(lower=~-1, upper=~crim+zn+indus+nox+rm+age+dis+rad+tax+ptratio+b+lstat))
summary(bh.step)
plot(bh.stemp)
plot(bh.step)
bh.lm2 <- lm(medv~crim + nox + rm + dis + rad + tax +
ptratio + b + lstat, data=bh); summary(bh.lm2); plot(bh.lm2)
bh.lm2 <- lm(medv~nox + rm + dis + rad +
ptratio + b + lstat, data=bh); summary(bh.lm2); plot(bh.lm2)
bh.lm2 <- lm(medv~nox + rm + dis +
ptratio + b + lstat, data=bh); summary(bh.lm2); plot(bh.lm2)
bh.lm2 <- lm(medv~nox + rm + dis +
ptratio + lstat, data=bh); summary(bh.lm2); plot(bh.lm2)
bh.lm2 <- lm(medv~nox + dis +
ptratio + lstat, data=bh); summary(bh.lm2); plot(bh.lm2)
bh.lm2 <- lm(medv~
ptratio + lstat, data=bh); summary(bh.lm2); plot(bh.lm2)
bh.lm2 <- lm(medv~nox + dis +
ptratio + lstat, data=bh); summary(bh.lm2); plot(bh.lm2)
bh.lm2 <- lm(medv~nox + rm + dis +
ptratio + lstat, data=bh); summary(bh.lm2); plot(bh.lm2)
b +
bh.lm2 <- lm(medv~nox + rm + dis +
ptratio + b + lstat, data=bh); summary(bh.lm2); plot(bh.lm2)
bh.lm2 <- lm(medv~nox + rm + dis + rad +
ptratio + b + lstat, data=bh); summary(bh.lm2); plot(bh.lm2)
bh.lm2 <- lm(medv~nox + rm + dis +
ptratio + b + lstat, data=bh); summary(bh.lm2); plot(bh.lm2)
bh.lm2 <- lm(medv~crim + nox + rm + dis + rad +
ptratio + b + lstat, data=bh); summary(bh.lm2); plot(bh.lm2)
+ tax
bh.lm2 <- lm(medv~crim + nox + rm + dis + rad + tax +
ptratio + b + lstat, data=bh); summary(bh.lm2); plot(bh.lm2)
bh.lm2 <- lm(medv~crim + zn + nox + rm + dis + rad + tax +
ptratio + b + lstat, data=bh); summary(bh.lm2); plot(bh.lm2)
bh.lm2 <- lm(medv~crim + zn + nox + rm + dis + rad + tax +
ptratio + b + lstat, data=bh); summary(bh.lm2); plot(bh.lm2)
bh.lm2 <- lm(medv~crim + zn + nox + rm + dis + rad + tax +
ptratio + b + lstat, data=bh); summary(bh.lm2); plot(bh.lm2)
bh.lm2 <- lm(medv~crim + zn + rm + dis + rad + tax +
ptratio + b + lstat, data=bh); summary(bh.lm2); plot(bh.lm2)
bh.lm2 <- lm(medv~zn + rm + dis + rad + tax +
ptratio + b + lstat, data=bh); summary(bh.lm2); plot(bh.lm2)
bh.lm2 <- lm(medv~rm + dis + rad + tax +
ptratio + b + lstat, data=bh); summary(bh.lm2); plot(bh.lm2)
bh.lm2 <- lm(medv~rm + dis + tax +
ptratio + b + lstat, data=bh); summary(bh.lm2); plot(bh.lm2)
bh.lm2 <- lm(medv~rm + dis +
ptratio + b + lstat, data=bh); summary(bh.lm2); plot(bh.lm2)
bh.lm2 <- lm(medv~crim + zn + nox + rm + dis + rad + tax +
ptratio + b + lstat, data=bh); summary(bh.lm2); plot(bh.lm2)
data <- read.csv("..\\..\\..\\data\\hdtv.csv", header=T)
data <- read.csv("data\\hdtv.csv", header=T)
data <- read.csv("검정2\\hdtv.csv", header=T)
str(data)
View(data)
View(data)
str(data)
x <- data$user.id
rm(x)
data$buy2[data$buy==2] <- "2:구매"
summary(data)
dim(data)
data$buy2[data$buy==1] <- "1:구매안함"
data$buy2[data$buy==2] <- "2:구매"
View(data)
View(data)
table(data$buy)
data_tbl <- table(data$buy2)
data_tbl
data_tbl[1]
data_tbl[2]
binom.test(c(data_tbl[2],data_tbl[1]), p=0.15, alternative="two.sided", conf.level=0.95)
binom.test(c(data_tbl[2],data_tbl[1]), p=0.15, alternative="greater", conf.level=0.95)
knitr::opts_chunk$set(echo = TRUE)
# 2. 방향성을 갖는 단측가설 검정
binom.test(c(136,14), p=0.8, alternative="greater", conf.level = 0.95)
binom.test(c(data_tbl[2],data_tbl[1]), p=0.15, alternative="greater", conf.level=0.95)
binom.test(c(data_tbl[2],data_tbl[1]), p=0.15, alternative="less", conf.level=0.95)
binom.test(c(data_tbl[2],data_tbl[1]), p=0.15, alternative="two.sides", conf.level=0.95)
binom.test(c(data_tbl[2],data_tbl[1]), p=0.15, alternative="two.sided", conf.level=0.95)
binom.test(c(data_tbl[2],data_tbl[1]), p=0.15, alternative="greater", conf.level=0.95)
binom.test(c(data_tbl[2],data_tbl[1]), p=0.2, alternative="greater", conf.level=0.95)
binom.test(c(data_tbl[2],data_tbl[1]), p=0.1, alternative="greater", conf.level=0.95)
binom.test(c(data_tbl[2],data_tbl[1]), p=0.15, alternative="greater", conf.level=0.95)
binom.test(c(data_tbl[2],data_tbl[1]), p=0.15, alternative="greater", conf.level=0.95)
data <- read.csv("검정2\\student_height.csv", header=T)
dim(data)
head(data)
summary(data)
str(data)
str(data);head(data)
shapiro.test(data$height)
?t.test
# Shapiro-Wilk normality test
#
# data:  data$height
# W = 0.88711, p-value = 0.0001853
#
# 정규분포를 따르므로 t.test 이용
t.test(data$height, mu=148.5, alternative="two.sided", conf.level=0.95)
wilcox.test(data$height, mu=148.5, alternative="two.sided", conf.level=0.95)
data <- read.csv("검정2\\sample.csv", header=T)
str(data)
summary(data)
head(data); str(data)
View(data)
View(data)
data <- data[!is.na(data$score)]
data <- data[,!is.na(data$score)]
data[!is.na(data$score)]
data[!is.na(data$score),]
data <- data[!is.na(data$score),]
summary(data)
library(dplyr)
data <- read.csv("..\\..\\..\\03stat_!\\one_sample.csv", header=T)
str(data); head(data)
data <- read.csv("..\\..\\..\\03stat_!\\one_sample.csv", header=T)
data <- read.csv("..\\..\\..\\03stat_!\\one_sample.csv", header=T)
str(data); head(data)
x <- data$time
# 데이터 분포 확인, 결측치 제거
summary(x)
mean(x)
# 데이터 정제
mean(x, na.rm=T)
x1 <- na.omit(x); mean(x1)
# 정규분포 검정
shapiro.test(x1)
data$gender2[data$gender==1] <- "1:남"
data$gender2[data$gender==2] <- "2:여"
x <- data$gender2
data$gender2[data$gender==1] <- "1:남"
data$gender2[data$gender==2] <- "2:여"
data$survey2[data$survey==0] <- "0:불만족"
data$survey2[data$survey==1] <- "1:만족"
table(data$gender2, data$survey2)
data_tbl <- table(data$gender2, data$survey2)
data_tbl[1]
data_tbl[1,]
data_tbl$sum <- apply(data_tbl, 1, sum)
data_tbl
data_tbl$sum <- apply(data_tbl, 2, sum)
data_tbl <- table(data$gender2, data$survey2)
data_tbl$sum <- apply(data_tbl, 2, sum)
data_tbl <- table(data$gender2, data$survey2)
apply(data_tbl, 1, sum)
data_tbl$sum <- apply(data_tbl, 1, sum)
data_tbl <- table(data$gender2, data$survey2)
str(data_tbl)
total <- apply(data_tbl, 1, sum)
trial <- apply(data_tbl, 1, sum)
rm(list=ls())
data <- read.csv("검정2\\sample.csv", header=T)
head(data); str(data)
summary(data)
data <- data[!is.na(data$score),]
data$gender2[data$gender==1] <- "1:남"
data$gender2[data$gender==2] <- "2:여"
data$survey2[data$survey==0] <- "0:불만족"
data$survey2[data$survey==1] <- "1:만족"
data_tbl <- table(data$gender2, data$survey2)
trial <- apply(data_tbl, 1, sum)
trial[0]
trial[0,1]
trial
trial[1]
CrossTable(data$gender2, data$survey2)
CrossTable(data$gender2, data$survey2, chisq=T)
data
CrossTable(data$gender2, data$survey2, chisq=T)
# Pearson's Chi-squared test
# ------------------------------------------------------------
# Chi^2 =  0.7977941     d.f. =  1     p =  0.3717537
#
# Pearson's Chi-squared test with Yates' continuity correction
# ------------------------------------------------------------
# Chi^2 =  0.5232812     d.f. =  1     p =  0.4694454
qchisq(1 - 0.05, 1)
prop.test(data_tbl[,1], trial, alternative="two.sided", conf.level=0.95)
data_tbl
trial
prop.test(c(31,15), c(140,84), alternative="two.sided", conf.level=0.95)
prop.test(data_tbl[,1], trial, alternative="two.sided", conf.level=0.95)
data_tbl
data_tbl[,1]
trial
prop.test(c(31,15), c(140,87), alternative="two.sided", conf.level=0.95)
prop.test(data_tbl[,1], trial, alternative="two.sided", conf.level=0.95)
prop.test(c(31,15), c(140,87), alternative="two.sided", conf.level=0.95)
prop.test(data_tbl[,1], trial, alternative="two.sided", conf.level=0.95)
# 2-sample test for equality of proportions with continuity correction
#
# data:  data_tbl[, 1] out of trial
# X-squared = 0.52328, df = 1, p-value = 0.4694
# alternative hypothesis: two.sided
# 95 percent confidence interval:
#   -0.06533111  0.16336066
# sample estimates:
#   prop 1    prop 2
# 0.2214286 0.1724138
prop.test(data_tbl[,2], trial, alternative="two.sided", conf.level=0.95)
data <- read.csv("검정2\\method.csv", header=T)
str(data)
data <- data[!is.na(data$score),]
data
shapiro.test(data$score)
CrossTable(data$score)
CrossTable(data$method, data$score, chisq=T)
data
data <- read.csv("검정2\\method.csv", header=T)
str(data)
data <- data[!is.na(data$score),]
CrossTable(data$method, data$score, chisq=T)
shapiro.test(data$score)
subset1 <- data[data$method==1]
subset1 <- data[data$method==1,]
subset2 <- data[data$method==2,]
summary(subset1, subset2)
summary(subset1);summary(subset2)
shapiro.test(subset1$score)
shapiro.test(subset2$score)
shapiro.test(subset1$score)
shapiro.test(subset2$score)
var.test(subset1, subset2)
var.test(subset1, subset2, conf.level=0.95)
var.test(subset1)
subset1
var.test(subset1$score, subset2$score, conf.level=0.95)
t.test(subset1$score, subset2$score, var.equal = F, conf.level = 0.95)
t.test(subset1$score, subset2$score, var.equal = F, conf.level = 0.95)
# data:  subset1$score and subset2$score
# F = 1.0648, num df = 21, denom df = 34, p-value = 0.8494
# alternative hypothesis: true ratio of variances is not equal to 1
# 95 percent confidence interval:
#   0.502791 2.427170
# sample estimates:
#   ratio of variances
# 1.06479
# ------------------------------------------------------------
# p값 >> 0.05이므로 유의수준 0.05 하에서 두 집단은 등분산성을 따르지 않는다.
t.test(subset1$score, subset2$score, var.equal = F, conf.level = 0.95)
t.test(subset1$score, subset2$score, conf.level = 0.95)
result
t.test(subset1$score, subset2$score, var.equal=T,conf.level = 0.95)
data <- read.csv("검정2\\method.csv", header=T)
str(data)
data <- na.omit(data)
subset1 <- data[data$method==1,]
subset2 <- data[data$method==2,]
var.test(subset1$score, subset2$score, conf.level=0.95)
