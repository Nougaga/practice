train
model2 <- glm(vs~., data=data, family=binomial)
summary(model2)
# 6) 결과 비교
# 5) 변수 선택
train
# 5) 변수 선택
model2 <- glm(vs~., data=train, family=binomial)
summary(model2)
# 5) 변수 선택
str(train)
model2 <- glm(vs~mpg, data=train, family=binomial)
model2 <- glm(vs~mpg+cyl , data=train, family=binomial)
model2 <- glm(vs~mpg+cyl+disp, data=train, family=binomial)
model2 <- glm(vs~mpg+cyl+disp+hp, data=train, family=binomial)
model2 <- glm(vs~mpg+cyl+disp+hp+drat, data=train, family=binomial)
library(Hmisc)
Hmisc::rcorr(as.matrix(train), type="pearson")
library(corrgram)
corrgram::corrgram(as.matrix(train), upper.panel = panel.conf)
corrgram::corrgram(as.matrix(mtcars), upper.panel = panel.conf)
model2 <- glm(vs~mpg+cyl, data=train, family=binomial)
model2 <- glm(vs~mpg+cyl, data=train, family=binomial);model2
model2 <- glm(vs~mpg+cyl, data=train, family=binomial);summary(model2)
# 5) 변수 선택
str(train)
corrgram::corrgram(as.matrix(mtcars[,c(-2)]), upper.panel = panel.conf)
corrgram::corrgram(as.matrix(mtcars[,c(-2,-6)]), upper.panel = panel.conf)
# -2cyl -6wt
model2 <- glm(vs~mpg+disp+hp+drat+qsec+am+gear+carb, data=train, family=binomial)
corrgram::corrgram(as.matrix(mtcars[,c(-2,-6)]), upper.panel = panel.conf)
corrgram::corrgram(as.matrix(mtcars[,c(-2,-6,-9)]), upper.panel = panel.conf)
corrgram::corrgram(as.matrix(mtcars[,c(-2,-6,-8)]), upper.panel = panel.conf)
corrgram::corrgram(as.matrix(mtcars[,c(-2,-6,-10)]), upper.panel = panel.conf)
# -2cyl -6wt -10gear
model2 <- glm(vs~mpg+disp+hp+drat+qsec+am+carb, data=train, family=binomial)
# 5) 변수 선택
str(train)
corrgram::corrgram(as.matrix(mtcars[,c(-2,-6,-8,-10)]), upper.panel = panel.conf)
# -2cyl -6wt -10gear
model2 <- glm(vs~mpg+disp+drat+qsec+am+carb, data=train, family=binomial)
corrgram::corrgram(as.matrix(mtcars[,c(-2,-4,-6,-8,-10)]), upper.panel = panel.conf)
# -2cyl -4hp -6wt -8vs -10gear
model2 <- glm(vs~mpg+drat+qsec+am+carb, data=train, family=binomial)
corrgram::corrgram(as.matrix(mtcars[,c(-2,-3,-4,-6,-8,-10)]), upper.panel = panel.conf)
corrgram::corrgram(as.matrix(mtcars[,c(-2,-3,-4,-5,-6,-8,-10)]), upper.panel = panel.conf)
# -2cyl -4hp -6wt -8vs -10gear
model2 <- glm(vs~mpg+qsec+am+carb, data=train, family=binomial)
# -2cyl -4hp -6wt -8vs -10gear
model2 <- glm(vs~mpg+qsec+carb, data=train, family=binomial)
# -2cyl -4hp -6wt -8vs -10gear
model2 <- glm(vs~mpg+qsec+am+carb, data=train, family=binomial)
# -2cyl -4hp -6wt -8vs -10gear
model2 <- glm(vs~mpg+qsec+am, data=train, family=binomial)
corrgram::corrgram(as.matrix(mtcars[,c(-2,-3,-4,-5,-6,-8,-10,-11)]), upper.panel = panel.conf)
# -2cyl -4hp -6wt -8vs -10gear
model2 <- glm(vs~mpg+qsec+am, data=train, family=binomial)
# -2cyl -4hp -6wt -8vs -10gear
model2 <- glm(vs~mpg+qsec, data=train, family=binomial)
# -2cyl -4hp -6wt -8vs -10gear
model2 <- glm(vs~mpg+am, data=train, family=binomial)
# -2cyl -4hp -6wt -8vs -10gear
model2 <- glm(vs~mpg+qsec, data=train, family=binomial)
# -2cyl -4hp -6wt -8vs -10gear
model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial);summary(model2)
# -2cyl -4hp -6wt -8vs -10gear
model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
# -2cyl -4hp -6wt -8vs -10gear
model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+am+gear+carb, data=train, family=binomial)
corrgram::corrgram(as.matrix(mtcars[,c()]), upper.panel = panel.conf)
corrgram::corrgram(as.matrix(mtcars[,]), upper.panel = panel.conf)
corrgram::corrgram(as.matrix(mtcars[,c(-9)]), upper.panel = panel.conf)
corrgram::corrgram(as.matrix(mtcars[,c(-8)]), upper.panel = panel.conf)
model2 <- glm(vs~cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~mpg+cyl+hp+drat+wt+am+gear+carb, data=train, family=binomial)
# 1) 데이터 로딩 및 서브셋
data(iris)
head(iris);str(iris);dim(iris)
data <- iris[iris$Species != "virginica",]
?factor
data$Species <- factor(data$Species, levels=c("setosa","versicolor"), labels = c(1,2))
str(data$Species)
corrgram::corrgram(as.matrix(mtcars[,c(-8)]), upper.panel = panel.conf)
model2 <- glm(vs~mpg+hp+drat+wt+qsec+am+carb, data=train, family=binomial)
# 5) 변수 선택
str(train)
corrgram::corrgram(as.matrix(mtcars[,c(-8,-10)]), upper.panel = panel.conf)
corrgram::corrgram(as.matrix(mtcars[,c(-8,-10,-11)]), upper.panel = panel.conf)
model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am, data=train, family=binomial)
corrgram::corrgram(as.matrix(mtcars[,c(-8:-11)]), upper.panel = panel.conf)
model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec, data=train, family=binomial)
model2 <- glm(vs~mpg+cyl+disp+hp+drat+qsec, data=train, family=binomial)
model2 <- glm(vs~mpg+qsec, data=train, family=binomial)
model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial);summary(model2)
model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~mpg+cyl+disp, data=train, family=binomial)
model2 <- glm(vs~hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
corrgram::corrgram(as.matrix(mtcars[,c(-8)]), upper.panel = panel.conf)
# 5) 변수 선택
str(train)
model2 <- glm(vs~mpg+cyl+disp, data=train, family=binomial);summary(model2)
?step
model2 <- step(object=train, trace=F, direction='backward')
model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial);summary(model2)
model2 <- step(object=model2, trace=F, direction='backward')
corrgram::corrgram(as.matrix(mtcars[,c(-8)]), upper.panel = panel.conf)
model2 <- glm(vs~mpg+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
+cyl
model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~mpg+cyl+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~mpg+cyl+disp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
+hp
model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~mpg+cyl+disp+hp+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~mpg+cyl+disp+hp+drat+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+gear+carb, data=train, family=binomial)
model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+carb, data=train, family=binomial)
model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear, data=train, family=binomial)
corrgram::corrgram(as.matrix(mtcars[,c(9:11)]), upper.panel = panel.conf)
corrgram::corrgram(as.matrix(mtcars[,]), upper.panel = panel.conf)
model2 <- glm(vs~mpg+cyl+disp+hp+qsec+carb, data=train, family=binomial)
model2 <- glm(vs~mpg+cyl+disp+hp+qsec, data=train, family=binomial)
model2 <- glm(vs~cyl+disp+hp+qsec, data=train, family=binomial)
model2 <- glm(vs~cyl+hp+qsec, data=train, family=binomial)
model2 <- glm(vs~cyl+qsec, data=train, family=binomial)
vif(train)
library(car)
vif(train)
# model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~cyl, data=train, family=binomial);summary(model2)
# model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~cyl+qsec, data=train, family=binomial);summary(model2)
# model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~cyl, data=train, family=binomial);summary(model2)
# model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~cyl+hp, data=train, family=binomial);summary(model2)
# model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~cyl+hp, data=train, family=binomial);summary(model2)
# model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~cyl+mpg, data=train, family=binomial);summary(model2)
# model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~cyl+wt, data=train, family=binomial);summary(model2)
# model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~cyl+crab, data=train, family=binomial);summary(model2)
# model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~cyl+carb, data=train, family=binomial);summary(model2)
# model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~cyl+drat, data=train, family=binomial);summary(model2)
# model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~cyl+gear, data=train, family=binomial);summary(model2)
# model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~cyl+am, data=train, family=binomial);summary(model2)
# model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~cyl, data=train, family=binomial);summary(model2)
# model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~mpg+cyl, data=train, family=binomial);summary(model2)
# model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~mpg, data=train, family=binomial);summary(model2)
# model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~cyl, data=train, family=binomial);summary(model2)
# model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~disp, data=train, family=binomial);summary(model2)
# model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~hp, data=train, family=binomial);summary(model2)
# model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~cyl, data=train, family=binomial);summary(model2)
# model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model2 <- glm(vs~hp+wt, data=train, family=binomial);summary(model2)
# model2 <- glm(vs~mpg+cyl+disp+hp+drat+wt+qsec+am+gear+carb, data=train, family=binomial)
model$fitted.values
step <- step(model, direction = 'backward')
step <- step(model, direction = 'backward')
step <- step(model, direction = 'forward')
step <- step(model)
dia.ctree <- ctree(price~., data=train2)
# ggplot2의 diamonds 데이터셋을 활용하여,
# decision tree와 앙상블 모형을 적용,
# 모델링을 수행하고 정확도를 비교해보세요
#
# (단, price 컬럼을 다음과 같이 명목형으로 변경하여 수행하세요)
# (3분위(75%)이상이면 S등급, 2분위(50%)이상이면 A,
#   1분위수(25%)이상이면 B등급, 25%이하는 C등급)
library(ggplot2)
data(diamonds)
dia <- diamonds
str(dia)
summary(dia$price)
dia$price[dia$price >= 5324] <- 5324
dia$price[dia$price < 5324 & dia$price >= 2401] <- 2401
dia$price[dia$price < 2401 & dia$price >= 950] <- 950
dia$price[dia$price < 950] <- 0
dia$price <- factor(dia$price, levels=c(5324,2401,950,0), labels=c("S","A","B","C"))
dia <- as.data.frame(dia)
library(caret)
# 1. rpart::rpart
library(rpart)
library(rpart.plot)
idx1 <- createDataPartition(dia$price, p=0.7, list=F)
train1 <- dia[idx1,]
test1 <- dia[-idx1,]
dia.rpart <- rpart(price~., data=train1)
dia.rpart
prp(dia.rpart, type=2, extra=2, digits=3)
dia.rpart.pr <- predict(dia.rpart, newdata=test1, type='class')
confusionMatrix(dia.rpart.pr, test1$price)
# 2. party::ctree
library(party)
idx2 <- createDataPartition(dia$price, p=0.7, list=F)
train2 <- dia[idx2,]
test2 <- dia[-idx2,]
dia.ctree <- ctree(price~., data=train2)
dia.ctree
plot(dia.ctree)
library(tree)
library(randomForest)
prp(dia.rpart, type=2, extra=2, digits=3)
# plot(dia.ctree)
con <- ctree_control(maxdepth = 5)  # 사전 가지치기 (2층까지만)
dia.ctree.prn <- ctree(price~., data=train2, controls=con)
plot(dia.ctree.prn)
# dia.ctree <- ctree(price~., data=train2)
# dia.ctree
# plot(dia.ctree)
con <- ctree_control(maxdepth = 3)
dia.ctree.prn <- ctree(price~., data=train2, controls=con)
plot(dia.ctree.prn)
plotcp(dia.ctree)
plotcp(dia.rpart)
dia.rpart.prune <- prune(dia.rpart, cp=dia.rpart$cptable[3])
dia.rpart.prn <- prune(dia.rpart, cp=dia.rpart$cptable[3])
data(diamonds)
dia <- diamonds
str(dia)
summary(dia$price)
dia$price[dia$price >= 5324] <- 5324
dia$price[dia$price < 5324 & dia$price >= 2401] <- 2401
dia$price[dia$price < 2401 & dia$price >= 950] <- 950
dia$price[dia$price < 950] <- 0
dia$price <- factor(dia$price, levels=c(5324,2401,950,0), labels=c("S","A","B","C"))
dia <- as.data.frame(dia)
idx1 <- createDataPartition(dia$price, p=0.7, list=F)
train1 <- dia[idx1,]
test1 <- dia[-idx1,]
dia.rpart <- rpart(price~., data=train1)
dia.rpart
prp(dia.rpart, type=2, extra=2, digits=3)
dia.rpart.pr <- predict(dia.rpart, newdata=test1, type='class')
confusionMatrix(dia.rpart.pr, test1$price)
dia.rpart.prn <- prune(dia.rpart, cp=dia.rpart$cptable[3])
prp(dia.rpart, type=2, extra=2, digits=3)
dia.rpart.prn <- prune(dia.rpart, cp=dia.rpart$cptable[3])
prp(dia.rpart.prn, type=2, extra=2, digits=3)
dia.rpart.prn <- prune(dia.rpart, cp=dia.rpart$cptable[4])
prp(dia.rpart.prn, type=2, extra=2, digits=3)
plotcp(dia.rpart)
dia.rpart.prn <- prune(dia.rpart, cp=dia.rpart$cptable[4])
prp(dia.rpart.prn, type=2, extra=2, digits=3)
idx2 <- createDataPartition(dia$price, p=0.7, list=F)
train2 <- dia[idx2,]
test2 <- dia[-idx2,]
dia.ctree <- ctree(price~., data=train2)
dia.ctree
# plot(dia.ctree)
con <- ctree_control(maxdepth = 4)
dia.ctree.prn <- ctree(price~., data=train2, controls=con)
plot(dia.ctree.prn)
dia.ctree.pr <- predict(dia.ctree, newdata=test2, type='class')
dia.ctree.pr <- predict(dia.ctree, newdata=test2)
confusionMatrix(dia.ctree.pr, test2$price)
idx3 <- createDataPartition(dia$price, p=0.7, list=F)
train3 <- dia[idx3,]
test3 <- dia[-idx3,]
confusionMatrix(dia.rpart.pr, test1$price)
confusionMatrix(dia.ctree.pr, test2$price)
library(randomForest)
dia.tree <- tree(price~., data=train3)
dia.tree
dia.tree.pr <- predict(dia.tree, newdata=test3)
confusionMatrix(dia.tree.pr, test3$price)  #
dia.tree.pr <- predict(dia.tree, newdata=test3, type='class')
confusionMatrix(dia.tree.pr, test3$price)  #
plot(dia.tree)
text(dia.tree)
plot(dia.tree, compress=T)
plot(dia.tree)
plot(dia.tree)
text(dia.tree)
prp(dia.tree)
?plotcp
# 4. Ensemble : Random Forest
library(randomForest)
# 4. Ensemble : Bagging
library(adabag)
dia.bagging <- bagging(price~., data=dia, mfinal=10)
dia.bagging
dia.bagging$importance
length(dia$carat)
dia.bagging <- bagging(price~., data=dia, mfinal=100)
dia.bagging$importance
par(mfrow=c(1,2))
plot(dia.bagging$trees[[1]])
text(dia.bagging$trees[[1]])
plot(dia.bagging$trees[[11]])
text(dia.bagging$trees[[11]])
par(mfrow=c(1,2))
plot(dia.bagging$trees[[49]])
text(dia.bagging$trees[[49]])
plot(dia.bagging$trees[[49]])
text(dia.bagging$trees[[49]])
plot(dia.bagging$trees[[49]], margin=.2)
text(dia.bagging$trees[[49]])
plot(dia.bagging$trees[[49]], margin=.1)
text(dia.bagging$trees[[49]])
plot(dia.tree, margin=.1)
text(dia.tree)
plot(dia.tree)
text(dia.tree)
plot(dia.tree)
text(dia.tree)
plot(dia.bagging$trees[[49]], margin=.1)
text(dia.bagging$trees[[49]])
str(dia.bagging$trees)
str(dia.bagging$trees[[1]])
prp(dia$bagging$trees[[1]])
str(dia)
dia.bagging.pr <- predict(dia.bagging, newdata=dia[,-7])
dia.bagging.pr <- predict(dia.bagging, newdata=dia[,-7])
confusionMatrix(as.factor(dia.bagging.pr$class), as.factor(dia[,7]))
dia.bagging.pr <- predict(dia.bagging, newdata=dia[,-7])
confusionMatrix(as.factor(dia.bagging.pr$class), as.factor(dia[,7]))
dia[,7]
str(dia[,7])
dia.bagging.pr$class
dia.bagging.pr$class
factor(dia.bagging.pr$class)
factor(dia.bagging.pr$class, levels=c("S","A","B","C"))
confusionMatrix(factor(dia.bagging.pr$class, levels=c("S","A","B","C")), dia[,7])
# looking into model
summary(dia.bagging)
str(dia.bagging$votes)
str(dia.bagging)
str(dia.bagging$votes)
str(dia.bagging[[1]])
str(dia.bagging[1)
str(dia.bagging[1])
str(dia.bagging[1,])
str(dia.bagging[,1])
dia.bagging$votes
dia.bagging$samples[,1]
str(dia.bagging$samples[,1])
# checking sample data
bg_sample1 <- table(sort(dia.bagging$samples[,1]))
bg_sample1
bg_sample11 <- data.frame(idx=as.numeric(attributes(bg_sample1)$dimnames[[1]]),
freq=bg_sample1)
bg_sample11
attributes(bg_sample1)$dimnames[[1]]
bg_sample11 <- data.frame(idx=as.numeric(attributes(bg_sample1)$dimnames[[1]]),
freq=bg_sample1)
bg_sample11
str(bg_sample11)
attributes(bg_sample1)$dimnames[[1]]
bg_sample1
# checking sample data
bg_sample <- table(sort(dia.bagging$samples[,1]))
bg_sample
rm(bg_sample1)
idx6 <- createDataPartition(dia$price, p=0.7, list=F)
train6 <- dia[idx6,]
test6 <- dia[-idx6,]
length(dia)
dia.rf <- randomForest(price~., data=train6,
ntree=100, mtry=sqrt(length(dia)-1), importance=T)
dia.rf
dia.rf.pr <- predict(dia.rf, newdata=dia[,-7])
dia.rf.pr
dia.rf.pr <- predict(dia.rf, newdata=test6[,-7])
confusionMatrix(dia.rf.pr, test6[,7])
importance(dia.rf)
varImpPlot(dia.rf, main="varImpPlot of diamonds")
dia.rf <- randomForest(price~., data=train6,
ntree=5000, mtry=sqrt(length(dia)-1), importance=T)
dia.rf <- randomForest(price~., data=train6,
ntree=500, mtry=sqrt(length(dia)-1), importance=T)
dia.rf.pr <- predict(dia.rf, newdata=test6[,-7])
confusionMatrix(dia.rf.pr, test6[,7]) # Accuracy : 0.9336
importance(dia.rf)
varImpPlot(dia.rf, main="varImpPlot of diamonds")
varImpPlot(dia.rf, main="varImpPlot of diamonds")
knitr::opts_chunk$set(echo = TRUE)
# data load
data(iris)
# bagging
iris.bagging <- adabag::bagging(Species~., data=iris, mfinal=100)
# bagging
iris.bagging <- adabag::bagging(Species~., data=iris, mfinal=100)
iris.bagging$importance
# visualization
par(mfrow=c(1,2))
plot(iris.bagging$trees[[1]], margin=.2)
text(iris.bagging$trees[[1]])
plot(iris.bagging$trees[[1]], margin=.2)
# visualization
par(mfrow=c(1,2))
# data load
data(iris)
# bagging
iris.bagging <- adabag::bagging(Species~., data=iris, mfinal=100)
# visualization
par(mfrow=c(1,2))
plot(iris.bagging$trees[[1]], margin=.2)
text(iris.bagging$trees[[1]])
plot(iris.bagging$trees[[11]], margin=.2)
text(iris.bagging$trees[[11]])
# visualization
par(mfrow=c(1,2))
plot(iris.bagging$trees[[1]])
text(iris.bagging$trees[[1]])
knitr::opts_chunk$set(echo = TRUE)
iris.bagging$importance
# visualization
par(mfrow=c(1,2))
plot(iris.bagging$trees[[1]])
# ggplot2의 diamonds 데이터셋을 활용하여,
# decision tree와 앙상블 모형을 적용,
# 모델링을 수행하고 정확도를 비교해보세요
#
# (단, price 컬럼을 다음과 같이 명목형으로 변경하여 수행하세요)
# (3분위(75%)이상이면 S등급, 2분위(50%)이상이면 A,
#   1분위수(25%)이상이면 B등급, 25%이하는 C등급)
library(ggplot2)
data(diamonds)
dia <- diamonds
str(dia)
summary(dia$price)
dia$price[dia$price >= 5324] <- 5324
dia$price[dia$price < 5324 & dia$price >= 2401] <- 2401
dia$price[dia$price < 2401 & dia$price >= 950] <- 950
dia$price[dia$price < 950] <- 0
dia$price <- factor(dia$price, levels=c(5324,2401,950,0), labels=c("S","A","B","C"))
dia <- as.data.frame(dia)
library(caret)
# 1. Decision Tree : rpart::rpart()
library(rpart)
library(rpart.plot)
idx1 <- createDataPartition(dia$price, p=0.7, list=F)
train1 <- dia[idx1,]
test1 <- dia[-idx1,]
dia.rpart <- rpart(price~., data=train1)
dia.rpart
prp(dia.rpart, type=2, extra=2, digits=3)
dia.rpart.pr <- predict(dia.rpart, newdata=test1, type='class')
confusionMatrix(dia.rpart.pr, test1$price)  # Accuracy : 0.8417
plotcp(dia.rpart)
dia.rpart.prn <- prune(dia.rpart, cp=dia.rpart$cptable[4])
prp(dia.rpart.prn, type=2, extra=2, digits=3)
confusionMatrix(dia.ctree.pr, test2$price)  # Accuracy : 0.9227
library(ggplot2)
data(diamonds)
dia <- diamonds
str(dia)
summary(dia$price)
dia$price[dia$price >= 5324] <- 5324
dia$price[dia$price < 5324 & dia$price >= 2401] <- 2401
dia$price[dia$price < 2401 & dia$price >= 950] <- 950
dia$price[dia$price < 950] <- 0
dia$price <- factor(dia$price, levels=c(5324,2401,950,0), labels=c("S","A","B","C"))
dia <- as.data.frame(dia)
library(caret)
# 1. Decision Tree : rpart::rpart()
library(rpart)
library(rpart.plot)
idx1 <- createDataPartition(dia$price, p=0.7, list=F)
train1 <- dia[idx1,]
test1 <- dia[-idx1,]
dia.rpart <- rpart(price~., data=train1)
dia.rpart
prp(dia.rpart, type=2, extra=2, digits=3)
dia.rpart.pr <- predict(dia.rpart, newdata=test1, type='class')
confusionMatrix(dia.rpart.pr, test1$price)  # Accuracy : 0.8417
plotcp(dia.rpart)
dia.rpart.prn <- prune(dia.rpart, cp=dia.rpart$cptable[4])
prp(dia.rpart.prn, type=2, extra=2, digits=3)
# 2. Decision Tree : party::ctree()
library(party)
idx2 <- createDataPartition(dia$price, p=0.7, list=F)
train2 <- dia[idx2,]
test2 <- dia[-idx2,]
dia.ctree <- ctree(price~., data=train2)
dia.ctree
# plot(dia.ctree)
dia.ctree.pr <- predict(dia.ctree, newdata=test2)
confusionMatrix(dia.ctree.pr, test2$price)  # Accuracy : 0.9227
library(adabag)
dia.bagging <- bagging(price~., data=dia, mfinal=100)
dia.bagging$importance
plot(dia.bagging$trees[[49]], margin=.1)
text(dia.bagging$trees[[49]])
dia.bagging.pr <- predict(dia.bagging, newdata=dia[,-7])
confusionMatrix(factor(dia.bagging.pr$class, levels=c("S","A","B","C")),
dia[,7]) # Accuracy : 0.8378
library(randomForest)
idx6 <- createDataPartition(dia$price, p=0.7, list=F)
train6 <- dia[idx6,]
test6 <- dia[-idx6,]
set.seed(1984)
dia.rf <- randomForest(price~., data=train6,
ntree=500, mtry=sqrt(length(dia)-1), importance=T)
plot(dia.rf)
